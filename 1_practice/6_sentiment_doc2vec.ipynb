{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from sklearn.model_selection import train_test_split  \n",
    "import numpy as np\n",
    "import glob\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '../../imdb'\n",
    "train_pos_path = os.path.join(data_path,'train','pos')\n",
    "train_neg_path = os.path.join(data_path,'train','neg')\n",
    "train_unsup_path = os.path.join(data_path,'train','unsup')\n",
    "#test_pos_path = os.path.join(data_path,'test','pos')\n",
    "#test_neg_path = os.path.join(data_path,'test','neg')\n",
    "#test_unsup_path = os.path.join(data_path,'test','unsup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_text(path):\n",
    "    files = glob.glob(path+'/*.txt')\n",
    "    sentances = list()\n",
    "    for fi in files:\n",
    "        with open(fi) as f:\n",
    "            text = f.read()\n",
    "        sentances.append(text)\n",
    "    return sentances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pos_reviews = read_text(train_pos_path)\n",
    "train_neg_reviews = read_text(train_neg_path)\n",
    "train_unsup_reviews = read_text(train_unsup_path)\n",
    "#test_pos_reviews = read_text(test_pos_path)\n",
    "#test_neg_reviews = read_text(test_neg_path)\n",
    "#test_unsup_reviews = read_text(test_unsup_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(corpus):\n",
    "    punctuation = \"\"\".,?!:;(){}[]\"\"\"\n",
    "    corpus = [z.lower().replace('\\n','') for z in corpus]\n",
    "    corpus = [z.replace('<br />', ' ') for z in corpus]\n",
    "    \n",
    "    # treat punctuation as individual words \n",
    "    for c in punctuation:\n",
    "        corpus = [z.replace(c, ' %s '%c) for z in corpus]\n",
    "    corpus = [z.split() for z in corpus]\n",
    "    return corpus  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.concatenate((train_pos_reviews, train_neg_reviews),axis=0)\n",
    "y = np.concatenate((np.ones(len(train_pos_reviews)), np.zeros(len(train_neg_reviews))))\n",
    "x= clean_text(x)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000   20000\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train),\" \",len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "We do this by using the LabeledSentence method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "a dummy index of the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## use labeledSentence object\n",
    "#LabeledSentence = gensim.models.doc2vec.LabeledSentence\n",
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_corpus(reviews):\n",
    "    for i,doc in enumerate(reviews):\n",
    "        yield TaggedDocument(doc,[i])\n",
    "\n",
    "train_corpus = list(read_corpus(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from gensim.models import Doc2Vec\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185751837"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "size = 400\n",
    "\n",
    "model = Doc2Vec(size=size, min_count=2, iter=50)\n",
    "model.build_vocab(train_corpus)\n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185762610"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16000, 0.5273270010948181),\n",
       " (7256, 0.4762829840183258),\n",
       " (10868, 0.47512879967689514),\n",
       " (11088, 0.4725697338581085),\n",
       " (18840, 0.4579414427280426),\n",
       " (12502, 0.45151767134666443),\n",
       " (7169, 0.4514364004135132),\n",
       " (1340, 0.4424135684967041),\n",
       " (3230, 0.4380508065223694),\n",
       " (5637, 0.4369805157184601)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.most_similar(positive=[1],topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bad', 0.4046088755130768),\n",
       " ('dumb', 0.3904520273208618),\n",
       " ('silly', 0.3591079115867615),\n",
       " ('lame', 0.3406074345111847),\n",
       " ('ridiculous', 0.3390560746192932),\n",
       " ('implausible', 0.30531254410743713),\n",
       " ('corny', 0.2954520285129547),\n",
       " ('unbelievable', 0.290984183549881),\n",
       " ('laughable', 0.2862737476825714),\n",
       " ('boring', 0.2851186692714691)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"stupid\",topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dumb', 0.3871752917766571),\n",
       " ('bad', 0.38552621006965637),\n",
       " ('silly', 0.3671604096889496),\n",
       " ('ridiculous', 0.33124151825904846),\n",
       " ('laughable', 0.30433395504951477),\n",
       " ('boring', 0.3040004074573517),\n",
       " ('lame', 0.2810211777687073),\n",
       " ('predictable', 0.2790890336036682),\n",
       " ('awful', 0.27542972564697266),\n",
       " ('confusing', 0.2697737514972687)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"stupid\",topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get training set vectors from our models\n",
    "def getVecs(model, corpus, size):\n",
    "    vecs = [model.docvecs[z].reshape((1, size)) for z in range(len(x_train))]\n",
    "    return np.concatenate(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_dm = getVecs(model,x_train,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "lr = SGDClassifier(loss='log', penalty='l1')\n",
    "lr.fit(train_vecs_dm,y_train )\n",
    "\n",
    "print ('Test Accuracy: %.2f'%lr.score(train_vecs_dm, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
