{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow this blog post\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\data\\chengyu\\basics\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models \n",
    "from scripts.normalization import normalize_corpus\n",
    "import numpy as np\n",
    "from docx import Document\n",
    "import sys\n",
    "import os\n",
    "import gensim\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "import pickle\n",
    "import nltk\n",
    "from collections import Counter\n",
    "#import pyLDAvis\n",
    "#import pyLDAvis.gensim  # don't skip this\n",
    "import pickle\n",
    "python_root = './scripts'\n",
    "sys.path.insert(0, python_root)\n",
    "\n",
    "import normalization_spacy as util\n",
    "from contractions import CONTRACTION_MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample document ids: \n",
      " ['9781451823295', '9781462328451', '9781451806069', '9781451815733', '9781451814002'] \n",
      "\n",
      "sample paragraphs: \n",
      " 1. As a small, open, tourism-based economy, St. Lucia is highly vulnerable to exogenous shocks. Tourism accounts for over three-quarters of exports, and the import content of both consumption and foreign direct investment (FDI) is very high (Figure 1). The economy has been buffeted by the global economic downturn, which has hobbled the tourism and construction sectors, with potential spillovers to the financial sector.\n"
     ]
    }
   ],
   "source": [
    "doc_dict = pickle.load(open('./data/xml_docs.p', \"rb\")) \n",
    "ids = list(doc_dict.keys())\n",
    "print('sample document ids: \\n',ids[:5],'\\n')\n",
    "test_docs = doc_dict[ids[0]]\n",
    "print('sample paragraphs: \\n',test_docs.paras[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of paragraphs in the corpus: 255915\n"
     ]
    }
   ],
   "source": [
    "## faltten all paragraphs \n",
    "paras = [doc_dict[i].paras for i in ids]\n",
    "corpus = list()\n",
    "for ps in paras:\n",
    "    corpus.extend(ps)\n",
    "\n",
    "print('Total number of paragraphs in the corpus: {}'.format(len(corpus)))\n",
    "\n",
    "\n",
    "trigram_reviews_filepath = 'data/lemma_docs.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents in the corpus: 2381\n"
     ]
    }
   ],
   "source": [
    "## faltten all paragraphs by document\n",
    "paras = [doc_dict[i].paras for i in ids]\n",
    "corpus = [' '.join(p) for p in paras]\n",
    "print('Total number of documents in the corpus: {}'.format(len(corpus)))\n",
    "\n",
    "trigram_reviews_filepath = 'data/lemma_docs_by_doc.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and lemmatize corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_md\n",
    "nlp = en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## single / multi threaded \n",
    "n_core = 16 \n",
    "load = False \n",
    "\n",
    "if load:\n",
    "    with open(trigram_reviews_filepath, 'r', encoding='utf_8') as f:\n",
    "        docs_lemma = f.readlines()\n",
    "        docs_lemma = [d.strip('\\n').split() for d in docs_lemma]\n",
    "else:\n",
    "    if n_core == 1:\n",
    "        docs = [nlp(d) for d in corpus]\n",
    "        docs_lemma = [[token.lemma_ for token in doc if not util.punct_space(token) ] for doc in docs]\n",
    "    else:\n",
    "        with open(trigram_reviews_filepath, 'w', encoding='utf_8') as f:\n",
    "            for doc in nlp.pipe(corpus,batch_size=10000,n_threads=n_core):\n",
    "                docs_lemma = [token.lemma_ for token in doc if not util.punct_space(token)]\n",
    "                trigram_para = ' '.join(docs_lemma)\n",
    "                f.write(trigram_para + '\\n')\n",
    "\n",
    "        with open(trigram_reviews_filepath, 'r', encoding='utf_8') as f:\n",
    "            docs_lemma = f.readlines()\n",
    "            docs_lemma = [d.strip('\\n').split() for d in docs_lemma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(corpus[3])\n",
    "print(docs_lemma[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram and Trigram transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_phrase_model = False\n",
    "bigram_transformer_path = os.path.join('data','bigram_transformer')\n",
    "trigram_transformer_path = os.path.join('data','trigram_transformer')\n",
    "common_terms = ['a','an','of',',','i','about','to',\"with\", \"without\"]\n",
    "\n",
    "if train_phrase_model: \n",
    "    paras = util.phrase_detect_train(docs_lemma,min_count=10,threshold=15,common_terms=common_terms,phrase_model_save_path='./data/bigram')\n",
    "    paras = util.phrase_detect_train(paras,min_count=10,threshold=15,common_terms=common_terms,phrase_model_save_path='./data/trigram')\n",
    "else:\n",
    "    bigram_transformer = Phraser.load(bigram_transformer_path)\n",
    "    trigram_transformer = Phraser.load(trigram_transformer_path)\n",
    "    paras = util.phrase_detect(bigram_transformer,trigram_transformer,docs_lemma) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- exam phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram = Phraser.load('data/trigram')\n",
    "trigram_transformer = Phraser.load('data/trigram_transformer')\n",
    "for phrase, score in trigram.export_phrases(docs_lemma[:2]):\n",
    "     print(phrase,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/processed_corpus_by_doc.p','wb') as f:\n",
    "    pickle.dump(paras,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/processed_corpus.p','rb') as f:\n",
    "#     cs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
