{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\data\\chengyu\\basics\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models \n",
    "from scripts.normalization import normalize_corpus\n",
    "import numpy as np\n",
    "from docx import Document\n",
    "import sys\n",
    "import os\n",
    "import gensim\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "import pickle\n",
    "python_root = './scripts'\n",
    "sys.path.insert(0, python_root)\n",
    "\n",
    "import normalization_spacy as util\n",
    "from contractions import CONTRACTION_MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample document ids: \n",
      " ['9781451823295', '9781462328451', '9781451806069', '9781451815733', '9781451814002'] \n",
      "\n",
      "sample paragraphs: \n",
      " 1. As a small, open, tourism-based economy, St. Lucia is highly vulnerable to exogenous shocks. Tourism accounts for over three-quarters of exports, and the import content of both consumption and foreign direct investment (FDI) is very high (Figure 1). The economy has been buffeted by the global economic downturn, which has hobbled the tourism and construction sectors, with potential spillovers to the financial sector.\n"
     ]
    }
   ],
   "source": [
    "doc_dict = pickle.load(open('./data/xml_docs.p', \"rb\")) \n",
    "ids = list(doc_dict.keys())\n",
    "print('sample document ids: \\n',ids[:5],'\\n')\n",
    "test_docs = doc_dict[ids[0]]\n",
    "print('sample paragraphs: \\n',test_docs.paras[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of paragraphs in the corpus: 255915\n"
     ]
    }
   ],
   "source": [
    "## faltten all paragraphs \n",
    "paras = [doc_dict[i].paras for i in ids]\n",
    "corpus = list()\n",
    "for ps in paras:\n",
    "    corpus.extend(ps)\n",
    "\n",
    "print('Total number of paragraphs in the corpus: {}'.format(len(corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and lemmatize corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_md\n",
    "nlp = en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## single / multi threaded \n",
    "n_core = 30 \n",
    "if n_core == 1:\n",
    "    docs = [nlp(d) for d in corpus]\n",
    "    docs_lemma = [[token.lemma_ for token in doc if not util.punct_space(token) ] for doc in docs]\n",
    "else:\n",
    "    trigram_reviews_filepath = 'data/lemma_docs.txt'\n",
    "    with open(trigram_reviews_filepath, 'w', encoding='utf_8') as f:\n",
    "        for doc in nlp.pipe(corpus,batch_size=10000,n_threads=n_core):\n",
    "            docs_lemma = [token.lemma_ for token in doc if not util.punct_space(token)]\n",
    "            trigram_para = ' '.join(docs_lemma)\n",
    "            f.write(trigram_para + '\\n')\n",
    "    \n",
    "    with open(trigram_reviews_filepath, 'r', encoding='utf_8') as f:\n",
    "        docs_lemma = f.readlines()\n",
    "        docs_lemma = [d.strip('\\n').split() for d in docs_lemma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(trigram_reviews_filepath, 'r', encoding='utf_8') as f:\n",
    "    docs_lemma = f.readlines()\n",
    "    docs_lemma = [d.strip('\\n').split() for d in docs_lemma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Real GDP growth slowed in 2007-08. Spurred by preparations for the Cricket World Cup, St. Lucia’s economy grew by about 5 percent in 2006. However, slowing construction and tourism activity, together with a hurricane-induced contraction in banana exports, reduced growth to an estimated 1.7 percent and 0.7 percent in 2007 and 2008, respectively. The unemployment rate increased by three percentage points to 16.8 percent during the same period. Despite being underpinned by the regional currency board arrangement, annual inflation reached 7.2 percent in 2008, reflecting high international prices of energy and food. With the decline in these prices, inflation has fallen to 3.2 percent by end-March 2009.\n",
      "['4', 'real', 'gdp', 'growth', 'slow', 'in', '2007', '08', 'spur', 'by', 'preparation', 'for', 'the', 'cricket', 'world', 'cup', 'st.', 'lucia', '’s', 'economy', 'grow', 'by', 'about', '5', 'percent', 'in', '2006', 'however', 'slow', 'construction', 'and', 'tourism', 'activity', 'together', 'with', 'a', 'hurricane', 'induce', 'contraction', 'in', 'banana', 'export', 'reduce', 'growth', 'to', 'an', 'estimate', '1.7', 'percent', 'and', '0.7', 'percent', 'in', '2007', 'and', '2008', 'respectively', 'the', 'unemployment', 'rate', 'increase', 'by', 'three', 'percentage', 'point', 'to', '16.8', 'percent', 'during', 'the', 'same', 'period', 'despite', 'be', 'underpin', 'by', 'the', 'regional', 'currency', 'board', 'arrangement', 'annual', 'inflation', 'reach', '7.2', 'percent', 'in', '2008', 'reflect', 'high', 'international', 'price', 'of', 'energy', 'and', 'food', 'with', 'the', 'decline', 'in', 'these', 'price', 'inflation', 'have', 'fall', 'to', '3.2', 'percent', 'by', 'end', 'march', '2009']\n"
     ]
    }
   ],
   "source": [
    "print(corpus[3])\n",
    "print(docs_lemma[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram and Trigram transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform sentances to trigrams .........\n",
      "\n",
      "Phrase model training done.\n",
      "Transform sentances to trigrams .........\n",
      "\n",
      "Phrase model training done.\n"
     ]
    }
   ],
   "source": [
    "train_phrase_model = True\n",
    "bigram_transformer_path = os.path.join('data','bigram_transformer')\n",
    "trigram_transformer_path = os.path.join('data','trigram_transformer')\n",
    "\n",
    "if train_phrase_model: \n",
    "    paras = util.phrase_detect_train(docs_lemma,min_count=5,threshold=20,phrase_model_save_path='./data/bigram')\n",
    "    paras = util.phrase_detect_train(paras,min_count=5,threshold=10,phrase_model_save_path='./data/trigram')\n",
    "else:\n",
    "    bigram_transformer = Phraser.load(bigram_transformer_path)\n",
    "    trigram_transformer = Phraser.load(trigram_transformer_path)\n",
    "    paras = util.phrase_detect(bigram_transformer,trigram_transformer,sentances) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- exma phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'1',\n",
       " b'as',\n",
       " b'1_as',\n",
       " b'a',\n",
       " b'as_a',\n",
       " b'small_open',\n",
       " b'a_small_open',\n",
       " b'tourism',\n",
       " b'small_open_tourism',\n",
       " b'base',\n",
       " b'tourism_base',\n",
       " b'economy',\n",
       " b'base_economy',\n",
       " b'st._lucia',\n",
       " b'economy_st._lucia',\n",
       " b'be',\n",
       " b'st._lucia_be',\n",
       " b'highly_vulnerable',\n",
       " b'be_highly_vulnerable',\n",
       " b'to']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram = Phraser.load('data/trigram')\n",
    "pharses_list = list(trigram.vocab.keys())\n",
    "pharses_list[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254756"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trigram.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(file_path):\n",
    "    with open(file_path,'r') as f:\n",
    "        corpus = f.readlines()\n",
    "    \n",
    "    corpus = [c.strip('\\n') for c in corpus]\n",
    "    corpus = [c for c in corpus if len(c)> 10]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##read data\n",
    "file_path = 'input/doc_1.txt'\n",
    "corpus = read_txt(file_path)\n",
    "## preprocess text\n",
    "norm_tokenized_corpus = normalize_corpus(corpus,tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dictionary\n",
    "dictionary = corpora.Dictionary(norm_tokenized_corpus)\n",
    "# convert document into bow\n",
    "corpus_bow = [dictionary.doc2bow(text) for text in norm_tokenized_corpus]\n",
    "## comput tfidf feature vectors\n",
    "tfidf = models.TfidfModel(corpus_bow)\n",
    "corpus_tfidf = tfidf[corpus_bow]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Semantic Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## topic modeling \n",
    "total_topics = 7\n",
    "lsi = models.LsiModel(corpus_tfidf,\n",
    "                      id2word=dictionary,\n",
    "                      num_topics= total_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now you can see topic by index, words and weights \n",
    "print(lsi.show_topic(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, topic in lsi.print_topics(total_topics):\n",
    "    print('Topic #{}'.format(index+1))\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a better way to print \n",
    "def print_topics_gensim(topic_model, total_topics=1,\n",
    "                        weight_threshold=0.0001,\n",
    "                        display_weights=False,\n",
    "                        num_terms=None):\n",
    "    \n",
    "    for index in range(total_topics):\n",
    "        topic = topic_model.show_topic(index)\n",
    "        topic = [(word, round(wt,2)) \n",
    "                 for word, wt in topic \n",
    "                 if abs(wt) >= weight_threshold]\n",
    "        if display_weights:\n",
    "            print('Topic #'+str(index+1)+' with weights')\n",
    "            print (topic[:num_terms] if num_terms else topic)\n",
    "        else:\n",
    "            print ('Topic #'+str(index+1)+' without weights')\n",
    "            tw = [term for term, wt in topic]\n",
    "            print (tw[:num_terms] if num_terms else tw)\n",
    "        print\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_topics_gensim(topic_model=lsi,\n",
    "                    total_topics=total_topics,\n",
    "                    num_terms=5,\n",
    "                    display_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_topics = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = models.LdaMulticore(corpus_tfidf,\n",
    "                          id2word = dictionary,\n",
    "                          iterations = 1000,\n",
    "                          num_topics = total_topics,\n",
    "                          workers = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_topics_gensim(topic_model=lda,\n",
    "                   total_topics = total_topics,\n",
    "                   num_terms=10,\n",
    "                   display_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
