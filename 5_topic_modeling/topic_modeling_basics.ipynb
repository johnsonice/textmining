{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models \n",
    "from scripts.normalization import normalize_corpus\n",
    "import numpy as np\n",
    "from docx import Document\n",
    "import sys\n",
    "import os\n",
    "import gensim\n",
    "import pickle\n",
    "python_root = './scripts'\n",
    "sys.path.insert(0, python_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample document ids: \n",
      " ['9781451823295', '9781462328451', '9781451806069', '9781451815733', '9781451814002'] \n",
      "\n",
      "sample paragraphs: \n",
      " 1. As a small, open, tourism-based economy, St. Lucia is highly vulnerable to exogenous shocks. Tourism accounts for over three-quarters of exports, and the import content of both consumption and foreign direct investment (FDI) is very high (Figure 1). The economy has been buffeted by the global economic downturn, which has hobbled the tourism and construction sectors, with potential spillovers to the financial sector.\n"
     ]
    }
   ],
   "source": [
    "doc_dict = pickle.load(open('./data/xml_docs.p', \"rb\")) \n",
    "ids = list(doc_dict.keys())\n",
    "print('sample document ids: \\n',ids[:5],'\\n')\n",
    "test_docs = doc_dict[ids[0]]\n",
    "print('sample paragraphs: \\n',test_docs.paras[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of paragraphs in the corpus: 255915\n"
     ]
    }
   ],
   "source": [
    "## faltten all paragraphs \n",
    "paras = [doc_dict[i].paras for i in ids]\n",
    "corpus = list()\n",
    "for ps in paras:\n",
    "    corpus.extend(ps)\n",
    "\n",
    "print('Total number of paragraphs in the corpus: {}'.format(len(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_tokenized_corpus = normalize_corpus(corpus,tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " 'small',\n",
       " 'open',\n",
       " 'tourism',\n",
       " 'based',\n",
       " 'economy',\n",
       " 'st',\n",
       " 'lucia',\n",
       " 'highly',\n",
       " 'vulnerable',\n",
       " 'exogenous',\n",
       " 'shock',\n",
       " 'tourism',\n",
       " 'account',\n",
       " 'three',\n",
       " 'quarters',\n",
       " 'export',\n",
       " 'import',\n",
       " 'content',\n",
       " 'consumption',\n",
       " 'foreign',\n",
       " 'direct',\n",
       " 'investment',\n",
       " 'fdi',\n",
       " 'high',\n",
       " 'figure',\n",
       " '1',\n",
       " 'economy',\n",
       " 'buffet',\n",
       " 'global',\n",
       " 'economic',\n",
       " 'downturn',\n",
       " 'hobble',\n",
       " 'tourism',\n",
       " 'construction',\n",
       " 'sector',\n",
       " 'potential',\n",
       " 'spillover',\n",
       " 'financial',\n",
       " 'sector']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_tokenized_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(file_path):\n",
    "    with open(file_path,'r') as f:\n",
    "        corpus = f.readlines()\n",
    "    \n",
    "    corpus = [c.strip('\\n') for c in corpus]\n",
    "    corpus = [c for c in corpus if len(c)> 10]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##read data\n",
    "file_path = 'input/doc_1.txt'\n",
    "corpus = read_txt(file_path)\n",
    "## preprocess text\n",
    "norm_tokenized_corpus = normalize_corpus(corpus,tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dictionary\n",
    "dictionary = corpora.Dictionary(norm_tokenized_corpus)\n",
    "# convert document into bow\n",
    "corpus_bow = [dictionary.doc2bow(text) for text in norm_tokenized_corpus]\n",
    "## comput tfidf feature vectors\n",
    "tfidf = models.TfidfModel(corpus_bow)\n",
    "corpus_tfidf = tfidf[corpus_bow]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Semantic Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## topic modeling \n",
    "total_topics = 7\n",
    "lsi = models.LsiModel(corpus_tfidf,\n",
    "                      id2word=dictionary,\n",
    "                      num_topics= total_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now you can see topic by index, words and weights \n",
    "print(lsi.show_topic(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, topic in lsi.print_topics(total_topics):\n",
    "    print('Topic #{}'.format(index+1))\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a better way to print \n",
    "def print_topics_gensim(topic_model, total_topics=1,\n",
    "                        weight_threshold=0.0001,\n",
    "                        display_weights=False,\n",
    "                        num_terms=None):\n",
    "    \n",
    "    for index in range(total_topics):\n",
    "        topic = topic_model.show_topic(index)\n",
    "        topic = [(word, round(wt,2)) \n",
    "                 for word, wt in topic \n",
    "                 if abs(wt) >= weight_threshold]\n",
    "        if display_weights:\n",
    "            print('Topic #'+str(index+1)+' with weights')\n",
    "            print (topic[:num_terms] if num_terms else topic)\n",
    "        else:\n",
    "            print ('Topic #'+str(index+1)+' without weights')\n",
    "            tw = [term for term, wt in topic]\n",
    "            print (tw[:num_terms] if num_terms else tw)\n",
    "        print\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_topics_gensim(topic_model=lsi,\n",
    "                    total_topics=total_topics,\n",
    "                    num_terms=5,\n",
    "                    display_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_topics = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = models.LdaMulticore(corpus_tfidf,\n",
    "                          id2word = dictionary,\n",
    "                          iterations = 1000,\n",
    "                          num_topics = total_topics,\n",
    "                          workers = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_topics_gensim(topic_model=lda,\n",
    "                   total_topics = total_topics,\n",
    "                   num_terms=10,\n",
    "                   display_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
