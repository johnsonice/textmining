{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow this blog post\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\data\\chengyu\\basics\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models \n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import gensim\n",
    "import pickle\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "python_root = './scripts'\n",
    "sys.path.insert(0, python_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paras = pickle.load(open('./data/processed_corpus.p', \"rb\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'as', 'a', 'small', 'open', 'tourism', 'base', 'economy', 'st._lucia', 'be', 'highly_vulnerable_to_exogenous_shock', 'tourism', 'account', 'for', 'over', 'three_quarter', 'of', 'export', 'and', 'the', 'import_content', 'of', 'both', 'consumption', 'and', 'foreign_direct_investment', 'fdi', 'be', 'very', 'high', 'figure_1', 'the', 'economy', 'have', 'be', 'buffet', 'by', 'the', 'global', 'economic', 'downturn', 'which', 'have', 'hobble', 'the', 'tourism', 'and', 'construction', 'sector', 'with', 'potential', 'spillover', 'to', 'the', 'financial', 'sector']\n"
     ]
    }
   ],
   "source": [
    "print(paras[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Gensim for topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove stop words \n",
    "norm_tokenized_corpus = paras\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.extend(['-PRON-','percent','â€™s','would','also',\n",
    "                      'year','continue','include','give','may','new',\n",
    "                      'however','well','help','since'])\n",
    "norm_tokenized_corpus = [[token for token in p if token not in stopword_list] for p in norm_tokenized_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _flatten(container):\n",
    "    for i in container:\n",
    "        if isinstance(i, (list,tuple)):\n",
    "            for j in _flatten(i):\n",
    "                yield j\n",
    "        else:\n",
    "            yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('authority', 118184),\n",
       " ('growth', 106963),\n",
       " ('fiscal', 106076),\n",
       " ('bank', 102460),\n",
       " ('sector', 98047),\n",
       " ('policy', 97760),\n",
       " ('gdp', 88619),\n",
       " ('increase', 84369),\n",
       " ('financial', 81209),\n",
       " ('government', 80711),\n",
       " ('reform', 77477),\n",
       " ('debt', 74619),\n",
       " ('public', 71985),\n",
       " ('rate', 69359),\n",
       " ('staff', 69139),\n",
       " ('high', 62180),\n",
       " ('remain', 58921),\n",
       " ('need', 57091),\n",
       " ('tax', 56207),\n",
       " ('program', 55408),\n",
       " ('external', 54081),\n",
       " ('economic', 52831),\n",
       " ('support', 52515),\n",
       " ('improve', 52027),\n",
       " ('market', 49549),\n",
       " ('risk', 46722),\n",
       " ('exchange', 46034),\n",
       " ('project', 45026),\n",
       " ('investment', 44747),\n",
       " ('revenue', 44276)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(_flatten(norm_tokenized_corpus))\n",
    "wc = Counter(words)\n",
    "wc.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dictionary\n",
    "dictionary = corpora.Dictionary(norm_tokenized_corpus)\n",
    "dictionary.filter_extremes(no_below=5,no_above=0.5, keep_n=10000)\n",
    "# convert document into bow\n",
    "corpus_bow = [dictionary.doc2bow(text) for text in norm_tokenized_corpus]\n",
    "## comput tfidf feature vectors\n",
    "tfidf = models.TfidfModel(corpus_bow) # smartirs = 'atc' https://radimrehurek.com/gensim/models/tfidfmodel.html\n",
    "corpus_tfidf = tfidf[corpus_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a better way to print \n",
    "def print_topics_gensim(topic_model, total_topics=1,\n",
    "                        weight_threshold=0.0001,\n",
    "                        display_weights=False,\n",
    "                        num_terms=None):\n",
    "    \n",
    "    for index in range(total_topics):\n",
    "        topic = topic_model.show_topic(index,topn=num_terms)\n",
    "        topic = [(word, round(wt,4)) \n",
    "                 for word, wt in topic \n",
    "                 if abs(wt) >= weight_threshold]\n",
    "        if display_weights:\n",
    "            print('Topic #'+str(index+1)+' with weights')\n",
    "            print (topic[:num_terms] if num_terms else topic)\n",
    "        else:\n",
    "            print ('Topic #'+str(index+1)+' without weights')\n",
    "            tw = [term for term, wt in topic]\n",
    "            print (tw[:num_terms] if num_terms else tw)\n",
    "        print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_topics = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = models.LdaMulticore(corpus = corpus_tfidf,\n",
    "                          id2word = dictionary,\n",
    "                          iterations = 1000,\n",
    "                          num_topics = total_topics)#,\n",
    "                          #workers = 20) #alpha='auto',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -7.573914344961725\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda.log_perplexity(corpus_bow))  # a measure of how good the model is. lower the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.37673968309529193\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda, texts=norm_tokenized_corpus, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=2):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    n_topics = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = models.LdaMulticore(corpus = corpus,\n",
    "                          id2word = dictionary,\n",
    "                          random_state = 1,\n",
    "                          iterations = 1000,\n",
    "                          num_topics = num_topics,\n",
    "                          workers=25)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "        n_topics.append(num_topics)\n",
    "        print(\"{}: {}\".format(num_topics,coherence_values[-1]))\n",
    "    \n",
    "    return model_list, coherence_values,n_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5: 0.3670669920593702\n",
      "6: 0.4048856903927633\n",
      "7: 0.43304287873667796\n",
      "8: 0.4271937504602833\n",
      "9: 0.435415536813317\n",
      "10: 0.46305101244318625\n",
      "11: 0.4546452876134362\n",
      "12: 0.4536783969909961\n",
      "13: 0.446779069744696\n"
     ]
    }
   ],
   "source": [
    "# Can take a long time to run.\n",
    "model_list, coherence_values,n_topics = compute_coherence_values(dictionary=dictionary, corpus=corpus_tfidf,\n",
    "                                                        texts=norm_tokenized_corpus, start=5, limit=40, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(n_topics, coherence_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model_list[np.argmax(coherence_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_topics_gensim(topic_model=best_model,\n",
    "                   total_topics = total_topics,\n",
    "                   num_terms=10,\n",
    "                   display_weights=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_filepath = 'data/lda_res'\n",
    "best_model.save(lda_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join(paras[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our test document is document number 4310\n",
    "for index, score in sorted(best_model[corpus_tfidf[3]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, best_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model[corpus_tfidf[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda, corpus_bow, dictionary,n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(vis, './data/topic_lda.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
