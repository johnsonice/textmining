{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os \n",
    "import glob\n",
    "import re\n",
    "import  pickle\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from functools import partial\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def useless_words(delete_words,target):\n",
    "    for w in delete_words:\n",
    "        if w in target:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def process_documents(f):\n",
    "    index, file = f \n",
    "    with open(file,'r',encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    text = replace_regex.sub(' ',text)\n",
    "    text = re.sub(r'\\(.*?\\d+.*?\\)|\\s\\s\\s\\s+\\d','',text)  # clean up things like '(box 1)' and  '     1'\n",
    "    sentances = sent_tokenize(text)\n",
    "    \n",
    "    clean_sentances= list()\n",
    "    for line in sentances:\n",
    "        if useless_words(delete_words,line):\n",
    "            tokens = word_tokenize(line)\n",
    "            if len(tokens)>5:\n",
    "                wl = [len(t) for t in tokens]\n",
    "                if max(wl)<30:\n",
    "                    line = number_regex.sub(' ',line)\n",
    "                    tokens = word_tokenize(line.lower())\n",
    "                    clean_sentances.append(tokens)\n",
    "    if index%1000 == 0: print('finished ', index)\n",
    "    return clean_sentances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished  0\n",
      "finished  3800\n",
      "finished  2700\n",
      "finished  3300\n",
      "finished  3900\n",
      "finished  3400\n",
      "finished  1100\n",
      "finished  4000\n",
      "finished  3500\n",
      "finished  2200\n",
      "finished  2800\n",
      "finished  4100\n",
      "finished  600\n",
      "finished  4200\n",
      "finished  3600\n",
      "finished  2900\n",
      "finished  3700\n",
      "finished  4300\n",
      "finished  3000\n",
      "finished  4400\n",
      "finished  1700\n",
      "finished  4900\n",
      "finished  3100\n",
      "finished  4500\n",
      "finished  2300\n",
      "finished  5000\n",
      "finished  4600\n",
      "finished  3200\n",
      "finished  5100\n",
      "finished  100\n",
      "finished  4700\n",
      "finished  5400\n",
      "finished  5200\n",
      "finished  1200\n",
      "finished  5500\n",
      "finished  4800\n",
      "finished  5300\n",
      "finished  2400\n",
      "finished  700\n",
      "finished  5600\n",
      "finished  2500\n",
      "finished  6500\n",
      "finished  1800\n",
      "finished  5900\n",
      "finished  200\n",
      "finished  6600\n",
      "finished  2600\n",
      "finished  800\n",
      "finished  1300\n",
      "finished  5700\n",
      "finished  6700\n",
      "finished  7000\n",
      "finished  7100\n",
      "finished  6800\n",
      "finished  5800\n",
      "finished  7200\n",
      "finished  1900\n",
      "finished  6900\n",
      "finished  7500\n",
      "finished  6000\n",
      "finished  900\n",
      "finished  7300\n",
      "finished  300\n",
      "finished  2000\n",
      "finished  1400\n",
      "finished  7400\n",
      "finished  2100\n",
      "finished  1000\n",
      "finished  8100\n",
      "finished  7600\n",
      "finished  400\n",
      "finished  1500\n",
      "finished  6100\n",
      "finished  9100\n",
      "finished  8200\n",
      "finished  8600\n",
      "finished  9200\n",
      "finished  8300\n",
      "finished  8700\n",
      "finished  1600\n",
      "finished  500\n",
      "finished  9700\n",
      "finished  9300\n",
      "finished  10200\n",
      "finished  10700\n",
      "finished  8800\n",
      "finished  8400\n",
      "finished  6200\n",
      "finished  9400\n",
      "finished  10800\n",
      "finished  8500\n",
      "finished  9800\n",
      "finished  7700\n",
      "finished  10300\n",
      "finished  9500\n",
      "finished  10900\n",
      "finished  8900\n",
      "finished  10400\n",
      "finished  6300\n",
      "finished  9900\n",
      "finished  11300\n",
      "finished  9600\n",
      "finished  11000\n",
      "finished  10500\n",
      "finished  11400\n",
      "finished  9000\n",
      "finished  6400\n",
      "finished  11800\n",
      "finished  11100\n",
      "finished  10000\n",
      "finished  12300\n",
      "finished  10600\n",
      "finished  7800\n",
      "finished  11500\n",
      "finished  12900\n",
      "finished  12400\n",
      "finished  11200\n",
      "finished  11900\n",
      "finished  10100\n",
      "finished  13900\n",
      "finished  13000\n",
      "finished  13400\n",
      "finished  12500\n",
      "finished  14500\n",
      "finished  13100\n",
      "finished  14000\n",
      "finished  14600\n",
      "finished  12000\n",
      "finished  11600\n",
      "finished  12600\n",
      "finished  13500\n",
      "finished  14700\n",
      "finished  13200\n",
      "finished  14800\n",
      "finished  14100\n",
      "finished  12700\n",
      "finished  14900\n",
      "finished  12100\n",
      "finished  15000\n",
      "finished  13600\n",
      "finished  12800\n",
      "finished  14200\n",
      "finished  15100\n",
      "finished  15500\n",
      "finished  11700\n",
      "finished  13300\n",
      "finished  15600\n",
      "finished  15200\n",
      "finished  14300\n",
      "finished  15300\n",
      "finished  15700\n",
      "finished  12200\n",
      "finished  13700\n",
      "finished  7900\n",
      "finished  14400\n",
      "finished  15400\n",
      "finished  15800\n",
      "finished  16100\n",
      "finished  16200\n",
      "finished  15900\n",
      "finished  16600\n",
      "finished  16300\n",
      "finished  16000\n",
      "finished  13800\n",
      "finished  16400\n",
      "finished  16500\n",
      "finished  16700\n",
      "finished  8000\n",
      "finished  16800\n",
      "finished  16900\n",
      "finished  17000\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "if __name__ =='__main__':\n",
    "    \n",
    "    ## run a small sample of test first \n",
    "    test = False\n",
    "    \n",
    "####################################\n",
    "## set up some global variables \n",
    "####################################\n",
    "\n",
    "    delete_words = ['____','DOCUMENT OF INTERNATIONAL MONETARY FUND','Download Date']\n",
    "    replace_regex = re.compile(r'\\uf0b7|\\x0c')\n",
    "    number_regex = re.compile(r'\\d+?\\.\\d+|\\.\\d+|\\d+-\\d+|\\d+/\\d+|\\d+/|-\\d+|\\d+|½|¼|¼|⅔|¾/') ## clean up all kinds of numbers\n",
    "    #test = '123.45 123.25 1234 .245 2015-218  -60 1/asdf 2/asdf  2021/22 ////'\n",
    "    #replace_regex.findall(test)\n",
    "\n",
    "    files_path = 'txt_files_finished/'\n",
    "    files = sorted(glob.glob(files_path+'*.txt'))\n",
    "    if len(files) == 0:\n",
    "        raise ValueError('could not find input files')\n",
    "        \n",
    "###############################\n",
    "## run text process in parellel\n",
    "###############################\n",
    "    ## multi process it \n",
    "    num_cores = os.cpu_count()\n",
    "    \n",
    "    ## see if we want to run a test first\n",
    "    if test == True: \n",
    "        files = files[:100]\n",
    "        num_cores = 2\n",
    "    else:\n",
    "        num_cores = os.cpu_count()\n",
    "    \n",
    "    #multi process unpacking\n",
    "    p = Pool(num_cores)\n",
    "    partial_unpack = partial(process_documents)\n",
    "    process_mp = p.map(partial_unpack,enumerate(files))\n",
    "    p.close()\n",
    "    p.join()\n",
    "    print('finish')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_results = [l for sublist in process_mp for l in sublist]\n",
    "pickle.dump(total_results,open(\"sentances.p\", \"wb\"))\n",
    "#total_results = pickle.load(open(\"sentances.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
